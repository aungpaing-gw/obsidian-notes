---
alias : Resnet
---

**Kaiming He, xiangyu Zhang, Shaoqing Ren, Jian Sun**
*Microsoft Research*

| Publications     | Paper Published Date | Cited By | Note Taken Date |
| ---------------- | -------------------- | -------- | --------------- |
| [Arxiv](https://arxiv.org/pdf/1512.03385), [CVPR 2016 ](https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html)| 2015 - 16            | 136,837  | 17 / Oct                |

## 1. Read Paper
### 1.1 Abstraction
Deeper Neural Networks are more difficult to train. This paper addresses the problem of degradation, which occurs at a deeper model, by using residual layers instead of plain layers. The residual layer is simply an identity shortcut layer, which empowers the model to learn identity function if required.

### 1.2 Challenges, Contributions and Approaches
### 1.3 Experiments and Results

## 2. Read Source Code
### 2.1 Sources
### 2.2 Details on the contribution part

## 3.Reconstruct source code
### 3.1 Git Repository

## 4. Reproduce Experiments
### 4.1 Select Experiments
### 4.2 Experiment Details
### 4.3 Experiment Results
### 4.4 Experiment Validation, Comparison

## 5. Modify, Twist Around
### 5.1 Hypothesis
### 5.2 Result of the experiment on Hypothesis

## 6. Conclusion
### 6.1 Credibility of the Model
### 6.2 Strong and constraints of model
### 6.3 Applications and future improvements
### 6.4 Personal Thought
